{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "historic-session",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries:\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "first-wheel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the path to our eye dataset: \n",
    "Directory = r'H:\\Drowsiness Detection\\dataset\\train'\n",
    "# specify two categories on which we want to train our data:\n",
    "CATEGORIES = ['Closed' , 'Open']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "level-spine",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting image size:\n",
    "img_size = 24\n",
    "data = []\n",
    "\n",
    "#iterating over each image and get the image in array form,\n",
    "for category in CATEGORIES:\n",
    "    folder = os.path.join(Directory,category)\n",
    "    label = CATEGORIES.index(category)\n",
    "    for img in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, img)\n",
    "        img_arr = cv2.imread(img_path)\n",
    "        img_arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2GRAY)\n",
    "        img_arr = cv2.resize(img_arr,(img_size, img_size),1)\n",
    "        data.append([img_arr , label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ready-drove",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1452"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the length of data:\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "japanese-reference",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we shuffle the data to get random images of open eyes and closed eyes:\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cognitive-purple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing features and label for training the model: \n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for features,label in data:\n",
    "    X.append(features)\n",
    "    Y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "answering-steel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#covert them into array:\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "headed-addiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data into system:\n",
    "pickle.dump(X , open('X.pkl' , 'wb'))\n",
    "pickle.dump(Y , open('Y.pkl' , 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "pretty-constitution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the image array:\n",
    "X = X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "scheduled-silver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.57254902, 0.54509804, 0.54901961, ..., 0.78431373,\n",
       "         0.76078431, 0.74901961],\n",
       "        [0.50980392, 0.49019608, 0.52156863, ..., 0.78823529,\n",
       "         0.77254902, 0.74117647],\n",
       "        [0.44313725, 0.42745098, 0.36078431, ..., 0.77647059,\n",
       "         0.76078431, 0.74901961],\n",
       "        ...,\n",
       "        [0.78823529, 0.81176471, 0.79607843, ..., 0.75294118,\n",
       "         0.7372549 , 0.72941176],\n",
       "        [0.78823529, 0.82745098, 0.78823529, ..., 0.76470588,\n",
       "         0.74117647, 0.73333333],\n",
       "        [0.79607843, 0.78039216, 0.78039216, ..., 0.76470588,\n",
       "         0.7372549 , 0.7254902 ]],\n",
       "\n",
       "       [[0.86666667, 0.85882353, 0.85490196, ..., 0.59215686,\n",
       "         0.4627451 , 0.76862745],\n",
       "        [0.85882353, 0.89411765, 0.85490196, ..., 0.59607843,\n",
       "         0.70588235, 0.7254902 ],\n",
       "        [0.89411765, 0.87058824, 0.89019608, ..., 0.78039216,\n",
       "         0.74117647, 0.77647059],\n",
       "        ...,\n",
       "        [0.87843137, 0.83137255, 0.80784314, ..., 0.52941176,\n",
       "         0.57254902, 0.76470588],\n",
       "        [0.89803922, 0.85098039, 0.82352941, ..., 0.56862745,\n",
       "         0.62352941, 0.80392157],\n",
       "        [0.89019608, 0.87058824, 0.8627451 , ..., 0.59215686,\n",
       "         0.6627451 , 0.8627451 ]],\n",
       "\n",
       "       [[0.23529412, 0.2627451 , 0.27843137, ..., 0.43529412,\n",
       "         0.47843137, 0.50980392],\n",
       "        [0.26666667, 0.24705882, 0.25882353, ..., 0.32156863,\n",
       "         0.38431373, 0.42352941],\n",
       "        [0.21568627, 0.23529412, 0.18039216, ..., 0.2745098 ,\n",
       "         0.2745098 , 0.38823529],\n",
       "        ...,\n",
       "        [0.25098039, 0.27058824, 0.26666667, ..., 0.31372549,\n",
       "         0.29411765, 0.28235294],\n",
       "        [0.30980392, 0.28627451, 0.29411765, ..., 0.30196078,\n",
       "         0.27058824, 0.29803922],\n",
       "        [0.30980392, 0.3254902 , 0.31764706, ..., 0.30980392,\n",
       "         0.31372549, 0.30588235]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.5254902 , 0.56862745, 0.56078431, ..., 0.07843137,\n",
       "         0.05882353, 0.0627451 ],\n",
       "        [0.54117647, 0.54509804, 0.52941176, ..., 0.10196078,\n",
       "         0.0745098 , 0.06666667],\n",
       "        [0.54117647, 0.50196078, 0.44313725, ..., 0.14509804,\n",
       "         0.0745098 , 0.09019608],\n",
       "        ...,\n",
       "        [0.60784314, 0.67058824, 0.69019608, ..., 0.58823529,\n",
       "         0.59607843, 0.59607843],\n",
       "        [0.63529412, 0.63921569, 0.6745098 , ..., 0.61176471,\n",
       "         0.6       , 0.63921569],\n",
       "        [0.6       , 0.63529412, 0.6745098 , ..., 0.61176471,\n",
       "         0.61960784, 0.61960784]],\n",
       "\n",
       "       [[0.31764706, 0.3372549 , 0.33333333, ..., 0.36078431,\n",
       "         0.36078431, 0.36078431],\n",
       "        [0.31764706, 0.33333333, 0.33333333, ..., 0.36862745,\n",
       "         0.36470588, 0.36470588],\n",
       "        [0.31764706, 0.31764706, 0.3372549 , ..., 0.37647059,\n",
       "         0.36862745, 0.36470588],\n",
       "        ...,\n",
       "        [0.35686275, 0.32941176, 0.31764706, ..., 0.21568627,\n",
       "         0.25882353, 0.3254902 ],\n",
       "        [0.36862745, 0.35686275, 0.32941176, ..., 0.2745098 ,\n",
       "         0.29803922, 0.32941176],\n",
       "        [0.36078431, 0.35686275, 0.35294118, ..., 0.30980392,\n",
       "         0.31372549, 0.3372549 ]],\n",
       "\n",
       "       [[0.44313725, 0.39607843, 0.36078431, ..., 0.48235294,\n",
       "         0.48235294, 0.50588235],\n",
       "        [0.43921569, 0.38431373, 0.37254902, ..., 0.49019608,\n",
       "         0.48235294, 0.52941176],\n",
       "        [0.45490196, 0.39607843, 0.36862745, ..., 0.51372549,\n",
       "         0.54509804, 0.57254902],\n",
       "        ...,\n",
       "        [0.55686275, 0.5372549 , 0.50980392, ..., 0.32941176,\n",
       "         0.33333333, 0.35686275],\n",
       "        [0.59607843, 0.52941176, 0.51764706, ..., 0.34117647,\n",
       "         0.34117647, 0.36470588],\n",
       "        [0.56862745, 0.55294118, 0.52156863, ..., 0.37254902,\n",
       "         0.37254902, 0.38039216]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "current-pasta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1452, 24, 24, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape the X array to (24,24,1)\n",
    "img_rows,img_cols = 24,24\n",
    "X = X.reshape(X.shape[0],img_rows,img_cols,1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "inner-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will be using keras to create the model:\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D , MaxPooling2D , Flatten , Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "soviet-hamilton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating model:\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64 , (3,3) , activation = 'relu' , input_shape= X.shape[1:]))\n",
    "model.add(MaxPooling2D((1,1)))\n",
    "\n",
    "model.add(Conv2D(64 , (3,3) , activation = 'relu'))\n",
    "model.add(MaxPooling2D((1,1)))\n",
    "\n",
    "model.add(Conv2D(64 , (3,3) , activation = 'relu'))\n",
    "model.add(MaxPooling2D((1,1)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "\n",
    "model.add(Dense(2, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "seven-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model that we have created\n",
    "model.compile(optimizer = 'adam' , loss = 'sparse_categorical_crossentropy' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "nasty-measurement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.6692 - loss: 0.5776 - val_accuracy: 0.9041 - val_loss: 0.2392\n",
      "Epoch 2/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9351 - loss: 0.1957 - val_accuracy: 0.9452 - val_loss: 0.1546\n",
      "Epoch 3/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9421 - loss: 0.1519 - val_accuracy: 0.9452 - val_loss: 0.1176\n",
      "Epoch 4/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9627 - loss: 0.0996 - val_accuracy: 0.9452 - val_loss: 0.1176\n",
      "Epoch 5/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9723 - loss: 0.0844 - val_accuracy: 0.9521 - val_loss: 0.1334\n",
      "Epoch 6/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9801 - loss: 0.0607 - val_accuracy: 0.9178 - val_loss: 0.1786\n",
      "Epoch 7/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9671 - loss: 0.0857 - val_accuracy: 0.9452 - val_loss: 0.1355\n",
      "Epoch 8/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9652 - loss: 0.0852 - val_accuracy: 0.9521 - val_loss: 0.0903\n",
      "Epoch 9/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9886 - loss: 0.0327 - val_accuracy: 0.9658 - val_loss: 0.1001\n",
      "Epoch 10/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9926 - loss: 0.0287 - val_accuracy: 0.9726 - val_loss: 0.0766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e2c67ac9b0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit X , Y to the model to see accuracy of model:\n",
    "model.fit(X, Y, epochs = 10 , validation_split = 0.1 , batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-exclusive",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "purple-worry",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# save model and architecture to single file\n",
    "model.save(\"custmodel.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
